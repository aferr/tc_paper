\section{Microarchitectural Timing Channels and their Sources}
\label{sec:tc_sources}
The baseline architecture is vulnerable to microarchitectural timing channels 
caused by shared resources including the private and shared caches, the on chip 
network, the system bus, and the main memory. Furthermore, data-dependent 
variations in the timing parameters of microarchitectural components can cause 
timing channels even in the absence of sharing. In general, all 
microarchitectural timing channels may be classified as state based timing 
channels, resource contention based timing channels, or direct observation 
timing channels. As we will show, the classification of a timing channel within 
this taxonomy directly implies which techniques may be used to control that 
channel. We later present approaches to address timing channels of each kind.

In a state based timing channel:
\begin{itemize}
    \item The time required to access a resource with state depends on the 
        contents of that state (i.e. it depends on previous system behavior).
    \item An adversary can observe the time required to complete requests to 
        that resource made by one software module(that it controls).
    \item Another software module operating on secret data can modify this 
        state, and these modifications can possibly affect the request timings 
        observable by the adversary.
    \item These modifications can possibly depend on the secret.
\end{itemize}
When all of these conditions are met, the timings that the adversary can 
observe correlate with the secret, and sensitive information may be leaked.

There is a resource contention based timing channel whenever:
\begin{itemize}
    \item A resource can concurrently service a finite number of requests and 
        this limitation can affect the time required to service a request (e.g.  
        if a request can be delayed because the resource is servicing another 
        request) regardless of state or previous system behaviour.
    \item An adversary can observe the time required for requests to that 
        resource made by one software module (that it controls).
    \item Another software module that directly operates on a secret contends 
        for the same resource and this contention can affect the timings 
        observable by the adversary.
    \item Usage of this resource by the software module operating on the secret 
        can possibly correlate with the secret.
\end{itemize}
Together, these conditions imply that the adversary can make requests to use a 
resource with a contention based timing channel and extract secrets from these 
timings. If a timing channel can satisfy the definition of a state based timing 
channel, it should not be considered a resource contention based timing 
channel.

If instead the adversary can directly observe the time required for the 
software module operating on a secret to complete any action (e.g. run an 
entire program or complete a memory request) that may be correlated with some 
secret, this is a direct observation timing channel. If the adversary can 
exploit the timing channel by measuring the timing of its own actions, it is 
not a direct observation timing channel. Note that in state based and resource 
contention based timing channels an adversary can only measure the timings of a 
software module that it controls, but not the timings of the software modules 
directly operating on a secret. The sets of direct observation, resource 
contention, and state based timing channels are strictly disjoint.

Direct observation timing channels are distinct from the seemingly similar 
external timing channels. An external timing channel is one that is exploited 
by an adversary that makes timing measurements from outside of the system (i.e.  
by an adversary that does not share any hardware with the victim) whereas an 
internal timing channel is exploited through measurements made within the 
system. In Bernstein's attack \cite{bernstein}, the adversary exploits the 
timing channel by sending requests to a remote system and measuring the time 
required to complete the request. This is an external timing channel since the 
victim resides on a separate machine from the adversary, and it is a direct 
observation timing channel since the adversary is measuring how long the victim 
machine takes to fulfill a request. However, not all direct observation timing 
channels are external. Suppose the system of interest is based on a TrustZone 
like system and a normal world application must make requests of the secure 
world to execute correctly. An adversarial normal world application can make 
requests of the secure world and measure the time required to fulfill the 
request. Since fulfilling the request is an action carried out by the victim 
rather than the adversary this is a direct observation timing channel, but 
since the adversary and victim share hardware the timing channel is internal.

The rest of this section classifies the timing channel vulnerabilities due to 
each microarchitectural component into this taxonomy, and provides elucidating 
examples of these classes of timing channels. Note that a microarchitectural 
component may cause multiple timing channels which may be of a different class 
necessitating countermeasures to address each channel.

\subsection{Private Caches}
\label{sec:priv_cache}
The baseline private caches are shared among software modules whenever a core 
context switches between them. Despite the lack of concurrent sharing, private 
caches cause information leakage between context switches and through variation 
in timing not due to sharing.

Private caches impose a state based timing channel even if each software module 
has a totally disjoint address space (i.e. no software module can read or write 
any memory address that another software module can read or write). Requests to 
the memory hierarchy for addresses that are stored in the cache (cache hits) 
are returned faster than requests that are not stored in the cache (cache 
misses). So, the time required to access the cache depends on its state. An 
adversary controlling a software module can use conventional time measurement 
libraries to record cache access timings and determine which requests are hits.
The adversary controlled software module can be context switched out for one 
that will operate on some secret. This other can read new memory addresses into 
the cache which may evict some of the old entries that occupied the cache. The 
memory addresses used by this module can depend on the actual data of the 
secret, for example, through a branch condition. (In the attack proposed by 
Bernstein \cite{bernstein} the addresses read by an AES algorithm depend on the 
secret key through sboxes). Therefore, this satisfies the definition of a state 
based timing channel.

The adversary can exploit this timing channel by loading an array from memory 
that occupies as many cache lines as possible. The adversary then waits until 
the virtual machine he or she controls is context switched out and replaced 
with the software module that will operate on the secret. This software module 
may evict some of the cache lines of the array. When the adversarial software 
module context switches back, the adversary can learn which cache lines were 
evicted by making requests to read each element of the array and measuring the 
timing. It will take longer to read the elements which were evicted. Unless the 
cache is fully associative, the particular cache lines that were evicted will 
depend on the addresses operated on by the victim software module. Even if the 
cache is fully associative, the adversary can use an array that completely 
fills the cache and learn the number of cache lines read by the adversary - a 
quantity that can also depend on a secret.

Additionally, private caches also cause direct observation timing channel 
vulnerabilities if the adversary can measure the duration of an event performed 
by a software module that operates on some secret and includes one or more 
private cache
accesses. In the DRM video playback usage case, an example of such an event is 
a function call in the secure world that handles a request made by the normal 
world. The adversary can measure the time between making the request (invoking
the monitor to context switch the adversarial software module out) and being 
context switched back in. The total time required to complete the function will 
depend on the cache hit ratio which depends on program control flow and 
therefore possibly the secret. This direct observation timing channel has the 
interesting property in that it requires no interference or resource sharing 
between the two software modules at all.
 
\subsection{TLBs and Branch Predictors}
As with private caches, TLBs are shared among software modules between context 
switches. The TLB effectively caches address translations, and since page table 
hits are faster than misses, it can be shown through similar reasoning as 
Section \ref{sec:priv_cache} that the TLB causes state based timing channels 
and direct observation timing channels. The branch predictor is also shared by 
software modules between context switching. It stores branch prediction history 
in a branch prediction table, the contents of which are used to decide whether 
or not a branch should be taken. This prediction can positively or adversely 
affect execution time, and space in the branch prediction history table is 
finite, so evictions must be made. Again, similar reasoning can be applied to 
see that the branch predictor also causes state based and termination timing 
channels.

\subsection{Shared Caches}
Shared caches cause timing channel vulnerabilities that are similar to the 
vulnerabilities of the private caches (the state based timing channel and the 
direct observation timing channel). However, unlike the private caches, shared 
caches are subject to interference due to concurrently executing software 
modules. This allows the attacker to have finer-grained control over when 
interference takes place, potentially allowing for faster exfiltration of 
secrets. However, since the shared cache is larger it has a higher access time, 
and since it is higher in the memory hierarchy the private cache reduces the 
chance of a shared cache access. Both of these factors decrease the 
exfiltration rate, so it is unclear if shared cache timing channels are more 
efficient than private cache timing channels.

\subsection{Main Memory}
The main memory is shared between concurrently executing software modules, and 
analogous to the timing disparity between cache hits and misses, page faults in 
main memory take substantially longer than accessing entries that are present 
in main memory. So the main memory has sources of timing channels that are 
similar to the shared cache. However, the memory controller has additional 
timing channels due to resource contention as well as other state based timing 
channels. Wang et. al. classify timing channel sources as queueing structure 
interference, scheduler arbitration interference, and DRAM device interference.  
In this section these timing channel sources are summarized, and it is shown 
that the timing channels of the memory controller may also be thought of as 
resource contention or state based timing channels.

The DRAM device contains several finite resources (e.g., the command bus, data
bus, banks, and ranks), and contention for these resources is resolved by the 
queueing structure and scheduler. Each of these resources causes a resource 
contention based timing channel that may be observed in both the queing 
structure and scheduler. For example, two requests to the same bank cannot
be scheduled at the same time causing a timing channel observable in the 
queueing structure. Suppose the queueing structure contains a request from a 
victim owned software module for a bank. If an adversarial software module 
issues a request to the same bank, it will be delayed, informing the adversary 
that such a victim request exists.  Similarly, contention for the command bus 
causes a timing channel that may be observed in the scheduler. If a request 
from one software module arrives at the scheduler in the same cycle as a 
request from another software module and for a different bank, one of the 
requests is scheduled and the other is delayed since only a single command can 
occupy the command bus at a time.

A memory controller queueing structure collects incoming requests for the DRAM 
and stores them in a queue until. As noted, timing channels due to contention 
for resources in the
DRAM may be observed in the queue. However, even if these timing channels are 
closed, there is still a distinct state based timing channel in the queue. To 
see this, suppose the resources of the DRAM are no longer finite, that is, the 
ranks, banks, command bus, and data bus can each handle infinitely many 
requests at the same time. (Though one may argue that the queue is no longer 
necessary at all under these circumstances, practical techniques to address the 
aforementioned channels do not involve infite resources and queues will still 
be necessary. The intent here is merely to show that there is still a distinct 
timing channel even in the absennce of this resource contention).
The state elements of the queue can accommodate only a finite number of 
requests. If the queue is completely filled, any incoming request must be 
stalled. Therefore, the time required to make a memory request depends on the 
state in the queueing structure. An adversary can measure the time required for 
its memory requests and learn if a victim software module has completely 
occupied the queue or not (since the delay will be greater if the queue is 
full). This can indicate whether or not a secret dependent control flow segment 
led the victim program to a memory intensive region of of the program or not.  
These conditions imply that the finite queue space induces a state based timing 
channel. Note that although one might be inclined to think of queue slots as 
finite resources, the timing varition that is observable here depends on the 
system behavior in previous cycles so it is not a resource contention based 
timing channel.

The resource contention timing channels for the ranks, banks, and buses may be 
observed in the scheduler as well. However, there is another distinct state 
based timing channel. Depending on the specific scheduler policy, one request 
will be issued by the scheduler potentially causing other requests to be 
delayed.  Often, this policy is designed to exploit row buffer locality. When a 
memory access takes place, the row being accessed is stored in a row buffer 
(sense amplifier). Accesses to rows that are already stored in the row buffer 
are faster than those which are not. The decisions made by the scheduler depend 
on this state (and therefore the behavior of the system in previous cycles).  
This causes a state based timing channel.

\subsection{On Chip Network \& System Bus}
This section must still be completed, but it is likely that these timing 
channels can be viewed as resource contention based timing channels.
